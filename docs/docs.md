# Техническое задание на систему веб-краулинга и обработки данных

## Общая архитектура системы

Система проектируется на основе **микросервисной архитектуры**: каждый сервис отвечает за свою функцию (принцип единственной ответственности). В высокоуровневой схеме предусмотрен балансировщик нагрузки, распределяющий входящие задачи между несколькими воркерами, отвечающими за обход и парсинг страниц. Каждая такая нода («Fetcher/Processor») извлекает данные из веб-страниц и сохраняет результаты в базу данных. Для внешнего интерфейса и координации взаимодействия сервисов используется API-шлюз, обеспечивающий авторизацию и распределение запросов между микросервисами.

*Пример упрощённой архитектуры системы веб-краулинга: балансировщик нагрузки, пул воркеров (Fetcher/Processor), хранилище данных и микросервисы с API-шлюзом (на схеме условно). При увеличении нагрузки можно горизонтально масштабировать воркеры (добавлять новые экземпляры сервисов).*

Каждый микросервис и компонент системы может разрабатываться независимо, что упрощает сопровождение и развертывание. Для обмена данными между сервисами рекомендуется использовать REST или gRPC, а для фоновых задач – очереди сообщений (например, RabbitMQ, Kafka или Redis Pub/Sub). Применение **контейнеризации и оркестрации** (Docker, Kubernetes) позволит быстро разворачивать и масштабировать систему.

## Веб-интерфейс и администрирование

Приложение должно предоставлять удобный **веб-интерфейс** для управления системой и визуализации результатов. Основные требования к интерфейсу:
* **Регистрация и авторизация**:
* **Настройки**: раздел для указания ресурсов (URL-списков, прокси-серверов), режима работы (параллельность потоков, обход сайтов), пути сохранения данных, форматов выходных файлов, шаблонов именования результатов. Возможность задания учётных данных для автоматической регистрации и входа на сайты (login/password и т. п.).
* **Рабочий процесс**: отображение **логов** работы (загружаемые страницы, ошибки, предупреждения), общая **аналитика** (число обработанных страниц, объем скачанных данных), уведомления об исключительных ситуациях.
* **Управление задачами**: список активных и завершённых **задач парсинга**, с прогрессом (например, глубина обхода, количество найденных/обработанных ссылок). Возможность запускать новые задачи и приостанавливать/удалять существующие.
* **История и отчёты**: хронологический журнал выполнения задач, а также возможность выгрузки отчётов по результатам парсинга (например, в формате CSV/JSON).
* **Доступ к данным**: интерфейс для экспорта/импорта данных из базы (SQL/JSON), просмотр и редактирование сохранённой информации (например, результаты парсинга, параметры задач). Безопасность администрирования обеспечивается разграничением прав доступа (учётные записи и роли).

Для реализации админ-панели рекомендуется использовать современные фреймворки (см. раздел *Фронтенд*) и обеспечить **отзывчивый дизайн**. Логирование и мониторинг интерфейса следует организовать в соответствии с лучшими практиками: выводить понятные сообщения об ошибках, фиксировать критические события и метрики использования (время отклика, количество запросов).

## Парсинг и сбор данных

Система выполняет следующие **функциональные задачи сбора данных**:

* **Извлечение текста**: сбор и парсинг любой HTML-страницы. Для этого используются стабильные парсеры (например, BeautifulSoup, lxml) с поддержкой HTML5. Необходимо уметь извлекать основной контент и метаданные (заголовки, теги, атрибуты), применяя шаблоны и фильтры, заданные пользователем.
* **Скачивание файлов**: загрузка файлов по заданным расширениям (например, PDF, DOCX, изображения) из обходимых страниц в приоритетном порядке. Реализовать фильтрацию по MIME-типу и маске URL. Лучше использовать потоковую загрузку (streaming) для крупных файлов, а также управление повторными попытками при временных ошибках.
* **Извлечение и фильтрация ссылок**: поиск внутренних и внешних ссылок в HTML-документе, с последующей фильтрацией по паттернам (регулярным выражениям или маскам URL). Игнорировать нежелательные домены и уже обработанные URL. Следует соблюдать «robots.txt» и ограничения по частоте запросов (политика вежливого краулинга).
* **Рекурсивный обход**: переход по ссылкам с контролем глубины (depth-limit). При инициализации задачи указывается максимальная глубина обхода и дополнительные правила (например, обход строго в пределах одного домена). Это предотвращает бесконечные циклы и гарантирует финиш задания после прохождения всех доступных уровней.
* **Плагины и фильтры для конкретных сайтов**: возможность добавлять пользовательские скрипты или модули обработки для известных структур сайтов. Например, особая обработка Wikipedia, государственных порталов («gov.ru») и др.: заранее прописанные селекторы или API-вызовы, ускоряющие извлечение данных. Такая модульность позволяет быстро адаптировать систему под новые требования без изменения ядра.
* **Конфигурирование правил парсинга**: система должна поддерживать загрузку настроек из файлов YAML/JSON и/или их редактирование через веб-интерфейс. В настройках указываются правила парсинга (селекторы, регулярные выражения), приоритеты задач, список игнорируемых URL и др. Это обеспечивает прозрачность и гибкость конфигурации без перекомпиляции кода.

Все сетевые операции должны происходить с учётом **периодичности и лимитов** (rate limiting), указанной в настройках, чтобы не нагружать целевые сайты. Кроме того, желательно реализовать «умную» очередность запросов (например, сначала – наиболее важные ссылки) и возможность перезапуска задач с места остановки.

## Дополнительные возможности и расширения

Система допускает расширение функциональности через дополнительные компоненты:

* **Безопасность и обход защита**: поддержка **прокси-серверов** для сокрытия реального IP, автоматическое чередование пользовательских **User-Agent** и других HTTP-заголовков. Использовать headless-браузеры или специализированные сервисы (например, Splash, Selenium, Puppeteer) для обхода сайтов с защитой от ботов и динамическим контентом. Это поможет избежать блокировок при агрессивном сканировании.
* **Статистика и метрики**: сбор и отображение метрик «сколько страниц/ссылок/файлов обработано». Встроенная аналитика загрузки системы (CPU/RAM, сетевой трафик) и логирования может помочь оптимизировать процесс парсинга. По возможности – интеграция с системами мониторинга (Prometheus/Grafana) для реального времени.
* **Плагины для популярных источников**: готовые модули для известных ресурсов (например, извлечение данных о законодательстве с gov.ru, парсинг страниц википедии). Такие плагины могут использовать официальные API или адаптированные скрипты, повышающие точность сбора.
* **Асинхронность и высокопроизводительность**: все сетевые операции и I/O нужно выполнять **асинхронно** (с помощью `asyncio`/`aiohttp`, `trio` или аналогов) для повышения пропускной способности. Асинхронный подход позволяет «висеть» на сетевых запросах параллельно, не блокируя другие задачи. Это существенно ускорит обход большого числа URL (особенно при ожидании ответов) и эффективнее использует ресурсы.

В целом, архитектура должна поддерживать **горизонтальное масштабирование**: при необходимости добавляются новые сервисы-парсеры или балансировщики, не затрагивая логику существующих компонентов. Применение микросервисов и асинхронности позволяет добиться высокой производительности и отказоустойчивости.

## Технологический стек (Бэкенд)

Основной стек серверной части включает:

* **Python 3.11+ с FastAPI**. FastAPI – современный высокопроизводительный фреймворк для создания REST API. Он использует асинхронный **Starlette/Uvicorn** под капотом и идеально подходит для задач с большим количеством одновременных запросов. FastAPI автоматически генерирует документацию API (OpenAPI/Swagger) и интегрируется с Pydantic для валидации входных данных.
* **SQLAlchemy** для работы с базой данных – популярный ORM с поддержкой декларативных моделей. В сочетании с Alembic это обеспечивает удобное управление миграциями схемы БД. Pydantic-модели используются для сериализации/валидации данных на уровне API.
* **PostgreSQL (версия ≥15)** – основное хранилище данных. Выбор PostgreSQL обусловлен его надёжностью и продвинутыми возможностями: хранение JSONB-документов, полнотекстовый поиск, расширения (например, PostGIS). В частности, встроенный полнотекстовый поиск избавляет от необходимости внешнего поискового движка для многих задач. Рекомендуется настроить **репликацию master–slave** для распределения нагрузки чтения.
* **Redis** – in-memory хранилище для кэша и очередей. Используется для быстрого хранения сессий пользователей и кэширования часто запрашиваемых данных. Также Redis-подобные системы (RabbitMQ, Kafka) могут быть применены для очередей фоновых задач и pub/sub (например, уведомления WebSocket).
* **Java Spring Boot** – альтернатива для крупных корпоративных сервисов. Spring Boot обеспечивает **корпоративную стабильность и безопасность** (аутентификация, транзакции, мониторинг) и хорошо масштабируется в больших системах. На Java можно реализовывать критичные модули (например, сложная бизнес-логика или интеграции с внешними системами).
* **Node.js + Express** – для легковесных API или прототипов сервисов с высокой нагрузкой на I/O. Node.js использует событийный цикл и подходит для микросервисов, обрабатывающих множество одновременных соединений.
* **Go (Golang)** – для микросервисов и компонентов, требующих предельной производительности и параллелизма (использует «горутины» для многопоточности). Go-компоненты компилируются в быстрые нативные бинарники и хорошо подходят, например, для обработки сетевого трафика или конвертации данных.
* **Rust** – для низкоуровневых и системных компонентов (например, быстрых парсеров или конвертеров). Rust обеспечивает безопасность памяти и высокую скорость, может использоваться для WebAssembly-модулей в фронтенде.
* **WebAssembly (WASM)** – в перспективе часть клиентских вычислений или визуальных модулей можно вынести в WASM. Инструменты wasm-pack и wasm-bindgen помогут интегрировать модули Rust/C в JavaScript-клиент через `wasm-bindgen` и `web-sys`.

Каждый микросервис должен быть независим: **отдельный Docker-контейнер**, единый репозиторий изменений. Рекомендуется соблюдать **единую политику деплоя** (CI/CD), автоматизированное тестирование и линтинг (например, `golangci-lint` для Go).

## Технологический стек (Фронтенд)

Пользовательский интерфейс (админ-панель) реализуется с использованием современных веб-технологий:

* **React + TypeScript** – обеспечивает безопасность типов и стабильность кода.
* **React Flow + Rete.js** – для визуальных редакторов и drag-and-drop (например, построение графов обработки или цепочек задач). React Flow упрощает создание узловых диаграмм, Rete.js – расширение для связи узлов визуально.
* **Vite** – сборщик и dev-сервер, обеспечивает быструю «горячую» перезагрузку (HMR) и оптимизированную сборку.
* **React Router** – маршрутизация по разделам SPA (настройки, задачи, отчёты и т. д.).
* UI-библиотеки (Ant Design или Material-UI) – готовые компоненты для форм, таблиц, диалогов и т. п., ускоряют разработку и улучшают внешний вид.
* **D3.js** – для сложных диаграмм и визуализации статистики (взаимодействия, графики загрузок). React Flow может использовать D3-пакеты для автоматической раскладки графов.
* **React Query (TanStack Query)** – управление запросами к API, автоматическое кэширование и обновление данных.
* **Zustand** – простая библиотека для глобального состояния в React, например, для хранения данных о текущей сессии пользователя.
* **WASM-взаимодействие** – при необходимости интерфейс может загружать WebAssembly-модули (например, для ускоренного парсинга или редактирования) через `wasm-bindgen` и `wasm-react`.

Фронтенд должен обеспечивать **кроссплатформенность** (адаптивный дизайн) и лёгкую поддержку: код в TypeScript, единый стиль кодирования, документация компонентов. Разработка должна следовать «Манифесту архитектуры» и внутренним стандартам команды.

## Хранилища данных и кэширование

* **Главная СУБД – PostgreSQL**. Описание структуры БД включает таблицы задач, результатов парсинга, логов и т.д. Помимо SQL-таблиц рекомендуется использовать столбцы типа JSONB для хранения гибких или полуструктурированных данных. Активно применять индексы по полям, а для полнотекстового поиска – встроенные механизмы PostgreSQL. Для отказоустойчивости – master–slave репликация, плановые бэкапы.
* **Redis** – in-memory кэш. Используется для: кэширования API-ответов (ускорение повторных запросов), хранения сессий и токенов пользователей, реализации брокера задач (очередей) и механизмов pub/sub (уведомления WebSocket-клиентов).
* **ClickHouse** – аналитическая колоночная СУБД для больших объёмов логов и статистики. Подходит для построения оперативных отчётов по собранным данным (например, агрегирование по времени, сложные фильтры). ClickHouse обычно используется *дополнительно* и в режиме считывания.
* **S3 или совместимый Blob-хранилище** – для файлов: шаблонов документов, результатов парсинга (файлы), сохранённых загрузок пользователей и бэкапов системы.
* **Кэширование**: продуманная схема кэширования ускоряет работу системы: данные о часто парсимых страницах или API-запросах можно хранить в Redis с истечением (TTL). Это снижает нагрузку на внешние сайты и БД. Использовать консистентное именование ключей и понятную политику очистки кэша.

Регулярно собирать **метрики использования** (количество вызовов сервисов, ошибки, время ответов) и хранимые агрегаты (предрасчёты) для генерации отчётов и планирования ресурсов. Логи запросов и действий пользователей должны сохраняться для аудитории (анализ активности, поиск проблем).

## Безопасность, политика доступа и аудит

Система должна учитывать **политику безопасности**:

* **Соблюдение robots.txt** и «вежливых» пауз между запросами, чтобы не нарушать правила сайтов и избежать блокировок.
* **Аутентификация/авторизация** пользователей: все операции в веб-интерфейсе доступны только зарегистрированным пользователям с соответствующими правами (роли – администратор, пользователь и т.д.).
* **Шифрование данных**: чувствительные параметры (пароли, токены) хранить в зашифрованном виде; передача по HTTPS.
* **Аудит действий**: вести журнал операций админа и сервисов (какие задачи запущены/остановлены, кто и когда менял настройки). Это поможет расследовать инциденты и проводить отладку.
* **Обновления и патчи**: следить за обновлениями библиотек и компонентов, чтобы закрыть уязвимости.

Использование сторонних библиотек и API должно соответствовать лицензиям и законам. В частности, при парсинге коммерческого контента важно учитывать правовые ограничения (авторские права, соглашения сайтов).

## Лицензирование и этапы разработки

На этапе разработки весь код публикуется под **MIT-лицензией** (для удобства совместной работы и проверки со стороны команды). После завершения и при переходе в коммерческий продукт система переходит на **закрытую (проприетарную)** лицензию. Документация и архитектурный манифест остаются внутренними (не публикуются).

Все компоненты следует оформлять в едином стиле, снабжать автоматическими тестами (юнит-тесты и интеграционные) и код-ревью. Разработчикам рекомендуется следовать выбранным внутренним стандартам качества и оформлять изменения в системе контроля версий с подробными комментариями.

**Источники:** приведены в тексте ссылки на статьи и руководства по микросервисам, FastAPI, PostgreSQL, архитектуре веб-краулинга и смежным темам.
